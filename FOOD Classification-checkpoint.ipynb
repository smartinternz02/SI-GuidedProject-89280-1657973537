{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;66;03m#used for numerical analysis\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;66;03m#open source used for both ML and DL for computation\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential \u001b[38;5;66;03m#it is a plain stack of layers\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers \u001b[38;5;66;03m#A layer consists of a tensor-in tensor-out computation function\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np#used for numerical analysis\n",
    "import tensorflow #open source used for both ML and DL for computation\n",
    "from tensorflow.keras.models import Sequential #it is a plain stack of layers\n",
    "from tensorflow.keras import layers #A layer consists of a tensor-in tensor-out computation function\n",
    "#Dense layer is the regular deeply connected neural network layer\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "#Faltten-used fot flattening the input or change the dimension\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D #Convolutional layer\n",
    "#MaxPooling2D-for downsampling the image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting parameter for Image Data agumentation to the traing data\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Data agumentation to the testing data\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2400 images belonging to 3 classes.\n",
      "Found 600 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#performing data agumentation to train data\n",
    "x_train=train_datagen.flow_from_directory(directory=r'E:\\FOOD Classification\\Food-Classification-from-Images-Using-Convolutional-Neural-Networks-in-Keras-using-Tensorflow-master\\dataset\\training_set'\n",
    "                                          ,target_size=(64,64),batch_size=32,class_mode='categorical')\n",
    "#performing data agumentation to test data\n",
    "x_test=test_datagen.flow_from_directory(directory=r'E:\\FOOD Classification\\Food-Classification-from-Images-Using-Convolutional-Neural-Networks-in-Keras-using-Tensorflow-master\\dataset\\test_set'\n",
    "                                        ,target_size=(64,64),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'french_fries': 0, 'pizza': 1, 'samosa': 2}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)#checking the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 800, 1: 800, 2: 800})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter as c\n",
    "c(x_train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model=Sequential()\n",
    "# adding model layer\n",
    "model.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation='relu'))#convolutional layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) #MaxPooling2D-for downsampling the input\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))#droping input randomly for preventing from overfiting\n",
    "\n",
    "\n",
    "model.add(Flatten())#flatten the dimension of the image\n",
    "model.add(Dense(32))#deeply connected neural network layers.\n",
    "model.add(Dense(3,activation='softmax'))#output layer with 3 neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                200736    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 210,979\n",
      "Trainable params: 210,979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()#summary of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-15660ad16113>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/80\n",
      "75/75 [==============================] - 106s 1s/step - loss: 1.0982 - accuracy: 0.4125 - val_loss: 0.9337 - val_accuracy: 0.5517\n",
      "Epoch 2/80\n",
      "75/75 [==============================] - 123s 2s/step - loss: 0.9269 - accuracy: 0.5529 - val_loss: 0.8210 - val_accuracy: 0.6000\n",
      "Epoch 3/80\n",
      "75/75 [==============================] - 242s 3s/step - loss: 0.8474 - accuracy: 0.6112 - val_loss: 0.9252 - val_accuracy: 0.5400\n",
      "Epoch 4/80\n",
      "75/75 [==============================] - 174s 2s/step - loss: 0.8182 - accuracy: 0.6396 - val_loss: 1.0349 - val_accuracy: 0.5567\n",
      "Epoch 5/80\n",
      "75/75 [==============================] - 60s 794ms/step - loss: 0.7738 - accuracy: 0.6542 - val_loss: 0.7489 - val_accuracy: 0.6783\n",
      "Epoch 6/80\n",
      "75/75 [==============================] - 55s 730ms/step - loss: 0.7185 - accuracy: 0.6796 - val_loss: 0.7720 - val_accuracy: 0.6817\n",
      "Epoch 7/80\n",
      "75/75 [==============================] - 55s 727ms/step - loss: 0.6998 - accuracy: 0.6963 - val_loss: 0.9861 - val_accuracy: 0.5950\n",
      "Epoch 8/80\n",
      "75/75 [==============================] - 46s 616ms/step - loss: 0.6810 - accuracy: 0.7000 - val_loss: 0.7379 - val_accuracy: 0.6933\n",
      "Epoch 9/80\n",
      "75/75 [==============================] - 48s 643ms/step - loss: 0.6899 - accuracy: 0.7000 - val_loss: 0.6407 - val_accuracy: 0.7300\n",
      "Epoch 10/80\n",
      "75/75 [==============================] - 51s 679ms/step - loss: 0.6424 - accuracy: 0.7400 - val_loss: 0.6546 - val_accuracy: 0.7300\n",
      "Epoch 11/80\n",
      "75/75 [==============================] - 46s 610ms/step - loss: 0.6183 - accuracy: 0.7354 - val_loss: 0.6318 - val_accuracy: 0.7483\n",
      "Epoch 12/80\n",
      "75/75 [==============================] - 49s 653ms/step - loss: 0.5662 - accuracy: 0.7738 - val_loss: 0.7800 - val_accuracy: 0.6933\n",
      "Epoch 13/80\n",
      "75/75 [==============================] - 46s 612ms/step - loss: 0.5506 - accuracy: 0.7683 - val_loss: 0.8968 - val_accuracy: 0.6433\n",
      "Epoch 14/80\n",
      "75/75 [==============================] - 44s 585ms/step - loss: 0.5400 - accuracy: 0.7725 - val_loss: 0.6925 - val_accuracy: 0.7200\n",
      "Epoch 15/80\n",
      "75/75 [==============================] - 44s 586ms/step - loss: 0.5162 - accuracy: 0.7900 - val_loss: 0.8508 - val_accuracy: 0.6833\n",
      "Epoch 16/80\n",
      "75/75 [==============================] - 49s 652ms/step - loss: 0.5160 - accuracy: 0.7763 - val_loss: 0.5659 - val_accuracy: 0.7900\n",
      "Epoch 17/80\n",
      "75/75 [==============================] - 46s 611ms/step - loss: 0.5030 - accuracy: 0.7987 - val_loss: 0.6008 - val_accuracy: 0.7750\n",
      "Epoch 18/80\n",
      "75/75 [==============================] - 73s 978ms/step - loss: 0.4637 - accuracy: 0.8062 - val_loss: 1.0475 - val_accuracy: 0.6567\n",
      "Epoch 19/80\n",
      "75/75 [==============================] - 63s 835ms/step - loss: 0.4847 - accuracy: 0.8021 - val_loss: 0.8303 - val_accuracy: 0.7150\n",
      "Epoch 20/80\n",
      "75/75 [==============================] - 55s 736ms/step - loss: 0.4466 - accuracy: 0.8158 - val_loss: 0.5143 - val_accuracy: 0.8067\n",
      "Epoch 21/80\n",
      "75/75 [==============================] - 44s 589ms/step - loss: 0.4743 - accuracy: 0.8004 - val_loss: 0.8525 - val_accuracy: 0.7233\n",
      "Epoch 22/80\n",
      "75/75 [==============================] - 46s 614ms/step - loss: 0.4656 - accuracy: 0.8125 - val_loss: 0.5322 - val_accuracy: 0.8017\n",
      "Epoch 23/80\n",
      "75/75 [==============================] - 47s 631ms/step - loss: 0.4347 - accuracy: 0.8304 - val_loss: 0.6830 - val_accuracy: 0.7650\n",
      "Epoch 24/80\n",
      "75/75 [==============================] - 83s 1s/step - loss: 0.4095 - accuracy: 0.8333 - val_loss: 0.7530 - val_accuracy: 0.7650\n",
      "Epoch 25/80\n",
      "75/75 [==============================] - 110s 1s/step - loss: 0.3820 - accuracy: 0.8421 - val_loss: 0.9365 - val_accuracy: 0.6933\n",
      "Epoch 26/80\n",
      "75/75 [==============================] - 168s 2s/step - loss: 0.3934 - accuracy: 0.8487 - val_loss: 0.6411 - val_accuracy: 0.7750\n",
      "Epoch 27/80\n",
      "75/75 [==============================] - 84s 1s/step - loss: 0.3614 - accuracy: 0.8596 - val_loss: 0.6670 - val_accuracy: 0.7700\n",
      "Epoch 28/80\n",
      "75/75 [==============================] - 46s 613ms/step - loss: 0.3897 - accuracy: 0.8471 - val_loss: 0.7377 - val_accuracy: 0.7483\n",
      "Epoch 29/80\n",
      "75/75 [==============================] - 46s 614ms/step - loss: 0.3749 - accuracy: 0.8525 - val_loss: 0.6257 - val_accuracy: 0.7933\n",
      "Epoch 30/80\n",
      "75/75 [==============================] - 44s 590ms/step - loss: 0.3666 - accuracy: 0.8554 - val_loss: 0.8003 - val_accuracy: 0.7517\n",
      "Epoch 31/80\n",
      "75/75 [==============================] - 45s 599ms/step - loss: 0.3422 - accuracy: 0.8667 - val_loss: 0.5662 - val_accuracy: 0.7883\n",
      "Epoch 32/80\n",
      "75/75 [==============================] - 45s 602ms/step - loss: 0.3437 - accuracy: 0.8650 - val_loss: 0.6088 - val_accuracy: 0.7950\n",
      "Epoch 33/80\n",
      "75/75 [==============================] - 48s 635ms/step - loss: 0.3094 - accuracy: 0.8800 - val_loss: 0.6493 - val_accuracy: 0.7983\n",
      "Epoch 34/80\n",
      "75/75 [==============================] - 45s 604ms/step - loss: 0.3116 - accuracy: 0.8750 - val_loss: 0.6818 - val_accuracy: 0.7867\n",
      "Epoch 35/80\n",
      "75/75 [==============================] - 53s 706ms/step - loss: 0.3003 - accuracy: 0.8858 - val_loss: 0.6018 - val_accuracy: 0.7983\n",
      "Epoch 36/80\n",
      "75/75 [==============================] - 50s 662ms/step - loss: 0.3220 - accuracy: 0.8629 - val_loss: 0.6607 - val_accuracy: 0.8067\n",
      "Epoch 37/80\n",
      "75/75 [==============================] - 53s 708ms/step - loss: 0.3634 - accuracy: 0.8571 - val_loss: 0.6126 - val_accuracy: 0.8133\n",
      "Epoch 38/80\n",
      "75/75 [==============================] - 52s 689ms/step - loss: 0.2818 - accuracy: 0.8929 - val_loss: 0.5671 - val_accuracy: 0.8250\n",
      "Epoch 39/80\n",
      "75/75 [==============================] - 50s 667ms/step - loss: 0.3050 - accuracy: 0.8800 - val_loss: 0.6745 - val_accuracy: 0.8050\n",
      "Epoch 40/80\n",
      "75/75 [==============================] - 52s 694ms/step - loss: 0.2915 - accuracy: 0.8829 - val_loss: 0.5565 - val_accuracy: 0.8333\n",
      "Epoch 41/80\n",
      "75/75 [==============================] - 51s 677ms/step - loss: 0.2720 - accuracy: 0.8900 - val_loss: 0.9313 - val_accuracy: 0.7450\n",
      "Epoch 42/80\n",
      "75/75 [==============================] - 55s 727ms/step - loss: 0.2821 - accuracy: 0.8913 - val_loss: 0.6002 - val_accuracy: 0.8167\n",
      "Epoch 43/80\n",
      "75/75 [==============================] - 48s 642ms/step - loss: 0.3064 - accuracy: 0.8867 - val_loss: 0.6089 - val_accuracy: 0.8033\n",
      "Epoch 44/80\n",
      "75/75 [==============================] - 50s 665ms/step - loss: 0.2480 - accuracy: 0.9083 - val_loss: 0.5486 - val_accuracy: 0.8400\n",
      "Epoch 45/80\n",
      "75/75 [==============================] - 50s 666ms/step - loss: 0.2571 - accuracy: 0.8950 - val_loss: 0.7478 - val_accuracy: 0.8150\n",
      "Epoch 46/80\n",
      "75/75 [==============================] - 52s 690ms/step - loss: 0.2228 - accuracy: 0.9133 - val_loss: 0.6371 - val_accuracy: 0.8317\n",
      "Epoch 47/80\n",
      "75/75 [==============================] - 49s 649ms/step - loss: 0.2611 - accuracy: 0.8975 - val_loss: 0.8204 - val_accuracy: 0.7733\n",
      "Epoch 48/80\n",
      "75/75 [==============================] - 49s 651ms/step - loss: 0.2659 - accuracy: 0.8996 - val_loss: 0.8839 - val_accuracy: 0.7817\n",
      "Epoch 49/80\n",
      "75/75 [==============================] - 51s 684ms/step - loss: 0.2582 - accuracy: 0.8979 - val_loss: 0.6582 - val_accuracy: 0.8217\n",
      "Epoch 50/80\n",
      "75/75 [==============================] - 49s 650ms/step - loss: 0.2298 - accuracy: 0.9154 - val_loss: 0.7812 - val_accuracy: 0.7933\n",
      "Epoch 51/80\n",
      "75/75 [==============================] - 50s 671ms/step - loss: 0.2327 - accuracy: 0.9112 - val_loss: 0.7530 - val_accuracy: 0.7967\n",
      "Epoch 52/80\n",
      "75/75 [==============================] - 51s 682ms/step - loss: 0.2343 - accuracy: 0.9042 - val_loss: 0.7866 - val_accuracy: 0.7967\n",
      "Epoch 53/80\n",
      "75/75 [==============================] - 47s 631ms/step - loss: 0.1966 - accuracy: 0.9279 - val_loss: 0.7111 - val_accuracy: 0.8050\n",
      "Epoch 54/80\n",
      "75/75 [==============================] - 50s 661ms/step - loss: 0.2508 - accuracy: 0.9054 - val_loss: 0.6300 - val_accuracy: 0.8367\n",
      "Epoch 55/80\n",
      "75/75 [==============================] - 49s 656ms/step - loss: 0.2449 - accuracy: 0.9046 - val_loss: 0.7233 - val_accuracy: 0.8333\n",
      "Epoch 56/80\n",
      "75/75 [==============================] - 51s 677ms/step - loss: 0.2261 - accuracy: 0.9162 - val_loss: 0.6133 - val_accuracy: 0.8283\n",
      "Epoch 57/80\n",
      "75/75 [==============================] - 50s 662ms/step - loss: 0.1983 - accuracy: 0.9237 - val_loss: 0.9362 - val_accuracy: 0.7717\n",
      "Epoch 58/80\n",
      "75/75 [==============================] - 51s 681ms/step - loss: 0.2295 - accuracy: 0.9117 - val_loss: 0.7679 - val_accuracy: 0.8200\n",
      "Epoch 59/80\n",
      "75/75 [==============================] - 51s 685ms/step - loss: 0.1773 - accuracy: 0.9333 - val_loss: 0.7122 - val_accuracy: 0.8233\n",
      "Epoch 60/80\n",
      "75/75 [==============================] - 54s 718ms/step - loss: 0.2075 - accuracy: 0.9246 - val_loss: 0.7061 - val_accuracy: 0.8083\n",
      "Epoch 61/80\n",
      "75/75 [==============================] - 48s 641ms/step - loss: 0.1892 - accuracy: 0.9292 - val_loss: 0.8423 - val_accuracy: 0.8100\n",
      "Epoch 62/80\n",
      "75/75 [==============================] - 50s 662ms/step - loss: 0.1661 - accuracy: 0.9379 - val_loss: 0.7632 - val_accuracy: 0.8167\n",
      "Epoch 63/80\n",
      "75/75 [==============================] - 50s 667ms/step - loss: 0.1839 - accuracy: 0.9275 - val_loss: 0.7710 - val_accuracy: 0.8217\n",
      "Epoch 64/80\n",
      "75/75 [==============================] - 50s 660ms/step - loss: 0.2015 - accuracy: 0.9212 - val_loss: 0.9662 - val_accuracy: 0.7900\n",
      "Epoch 65/80\n",
      "75/75 [==============================] - 52s 689ms/step - loss: 0.1972 - accuracy: 0.9221 - val_loss: 1.0379 - val_accuracy: 0.7833\n",
      "Epoch 66/80\n",
      "75/75 [==============================] - 47s 622ms/step - loss: 0.1835 - accuracy: 0.9325 - val_loss: 0.7455 - val_accuracy: 0.8250\n",
      "Epoch 67/80\n",
      "75/75 [==============================] - 87s 1s/step - loss: 0.1625 - accuracy: 0.9429 - val_loss: 0.7650 - val_accuracy: 0.8250\n",
      "Epoch 68/80\n",
      "75/75 [==============================] - 496s 7s/step - loss: 0.1837 - accuracy: 0.9375 - val_loss: 0.8161 - val_accuracy: 0.8233\n",
      "Epoch 69/80\n",
      "75/75 [==============================] - 145s 2s/step - loss: 0.1706 - accuracy: 0.9367 - val_loss: 0.6847 - val_accuracy: 0.8167\n",
      "Epoch 70/80\n",
      "75/75 [==============================] - 46s 615ms/step - loss: 0.1843 - accuracy: 0.9304 - val_loss: 0.8138 - val_accuracy: 0.8183\n",
      "Epoch 71/80\n",
      "75/75 [==============================] - 55s 737ms/step - loss: 0.1687 - accuracy: 0.9379 - val_loss: 0.9649 - val_accuracy: 0.8050\n",
      "Epoch 72/80\n",
      "75/75 [==============================] - 201s 3s/step - loss: 0.1496 - accuracy: 0.9450 - val_loss: 0.9875 - val_accuracy: 0.7950\n",
      "Epoch 73/80\n",
      "75/75 [==============================] - 56s 745ms/step - loss: 0.1973 - accuracy: 0.9292 - val_loss: 0.7603 - val_accuracy: 0.8300\n",
      "Epoch 74/80\n",
      "75/75 [==============================] - 54s 718ms/step - loss: 0.1689 - accuracy: 0.9392 - val_loss: 1.1936 - val_accuracy: 0.7617\n",
      "Epoch 75/80\n",
      "75/75 [==============================] - 46s 615ms/step - loss: 0.1851 - accuracy: 0.9267 - val_loss: 0.8924 - val_accuracy: 0.8067\n",
      "Epoch 76/80\n",
      "75/75 [==============================] - 42s 561ms/step - loss: 0.1602 - accuracy: 0.9362 - val_loss: 1.0581 - val_accuracy: 0.7900\n",
      "Epoch 77/80\n",
      "75/75 [==============================] - 48s 640ms/step - loss: 0.1605 - accuracy: 0.9413 - val_loss: 1.0142 - val_accuracy: 0.7833\n",
      "Epoch 78/80\n",
      "75/75 [==============================] - 42s 566ms/step - loss: 0.1551 - accuracy: 0.9388 - val_loss: 0.9434 - val_accuracy: 0.8117\n",
      "Epoch 79/80\n",
      "75/75 [==============================] - 42s 562ms/step - loss: 0.1322 - accuracy: 0.9529 - val_loss: 0.7624 - val_accuracy: 0.8317\n",
      "Epoch 80/80\n",
      "75/75 [==============================] - 42s 564ms/step - loss: 0.1434 - accuracy: 0.9446 - val_loss: 0.7905 - val_accuracy: 0.8350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f73a9c2ac0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit_generator(generator=x_train,steps_per_epoch = len(x_train),\n",
    "                    epochs=80, validation_data=x_test,validation_steps = len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-fef6456f365c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'food.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('food.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "model = load_model(\"food.h5\") #loading the model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image.load_img(r\"E:\\FOOD Classification\\Food-Classification-from-Images-Using-Convolutional-Neural-Networks-in-Keras-using-Tensorflow-master\\dataset\\samosa.jpg\",target_size= (64,64))#loading of the image\n",
    "x = image.img_to_array(img)#image to array\n",
    "x = np.expand_dims(x,axis = 0)#changing the shape\n",
    "pred = model.predict_classes(x)#predicting the classes\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'samosa'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=['french_fries', 'pizza', 'samosa']\n",
    "result=str(index[pred[0]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
